{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67130e40",
   "metadata": {
    "id": "67130e40"
   },
   "source": [
    "# ML Final Project \u2014 Guided Template (CIS 508)\n",
    "\n",
    "**Purpose:**  \n",
    "This notebook is your guide for the final project in Machine Learning in Business. You\u2019ll use it to organize your work and make sure each part of your project is clear and meaningful.\n",
    "\n",
    "Your project should follow four main steps:\n",
    "\n",
    "1. Project Overview \u2013 Introduce your topic, explain why it matters, and define your business problems.\n",
    "\n",
    "2. EDA & Data Insights \u2013 Explore your dataset, clean it, and highlight key patterns or findings that help you understand the problem.\n",
    "\n",
    "3. Modeling & Evaluation \u2013 Build and evaluate your machine learning models. Compare performance across models and explain what you learn from the results (at least, 2 models).\n",
    "\n",
    "4. Executive Summary \u2013 Summarize your main insights in plain language. Focus on what your results mean for decision-making or business strategy.\n",
    "\n",
    "Use this structure to keep your analysis focused, your writing organized, and your insights actionable.\n",
    "\n",
    "***Feel free to remove this part of the template when you finalize your project.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tj2z15TYZPoO",
   "metadata": {
    "id": "tj2z15TYZPoO"
   },
   "source": [
    "# Predicting California Housing Prices: A Machine Learning Approach to Real Estate Valuation\n",
    "\n",
    "**One-sentence description:**  \n",
    ">This project uses machine learning models to predict median house values in California based on geographic, demographic, and housing characteristics, helping real estate stakeholders make informed pricing and investment decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dfde32",
   "metadata": {
    "id": "c1dfde32"
   },
   "source": [
    "## Section 1 \u2014 Project Overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mBOsxuSmjESr",
   "metadata": {
    "id": "mBOsxuSmjESr"
   },
   "source": [
    "In this section, you\u2019ll introduce your project and explain what business problem you\u2019re trying to solve.  \n",
    "Please fill out each part clearly and concisely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hYHAI7s0hmFF",
   "metadata": {
    "id": "hYHAI7s0hmFF"
   },
   "source": [
    "### 1.1 Dataset and Problem Description\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nHLp3oPTjL4q",
   "metadata": {
    "id": "nHLp3oPTjL4q"
   },
   "source": [
    "- Indicate **which dataset** you selected (name and source).\n",
    "> **Dataset**: California Housing Prices  \n",
    "> **Source**: This dataset is based on the 1990 California census data and is commonly used in machine learning courses and competitions. The dataset contains information about housing districts in California, including geographic location, housing characteristics, and demographic information. It is available from various open data platforms and has been widely used for regression analysis and predictive modeling in real estate contexts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i5cF5Q3lmHB6",
   "metadata": {
    "id": "i5cF5Q3lmHB6"
   },
   "source": [
    "- Describe **the size of the dataset** (number of rows and columns).  \n",
    "> The dataset contains approximately **20,640 observations** (rows) and **10 features** (columns). This provides a substantial sample size for building robust machine learning models while maintaining computational efficiency. The dataset includes one target variable (median_house_value) and nine predictor variables covering geographic location, housing characteristics, and demographic factors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_0Y6x6ZymJL2",
   "metadata": {
    "id": "_0Y6x6ZymJL2"
   },
   "source": [
    "- **Introduce all variables**: provide a short description of each key variable and its meaning.\n",
    "> **Target Variable:**\n",
    "> - **median_house_value**: The median house value for households within a block (continuous, in US dollars). This is our target variable for prediction.\n",
    "> \n",
    "> **Predictor Variables:**\n",
    "> - **longitude**: Geographic longitude coordinate of the housing block (continuous, negative values indicate west of prime meridian)\n",
    "> - **latitude**: Geographic latitude coordinate of the housing block (continuous)\n",
    "> - **housing_median_age**: Median age of houses within the block (continuous, in years)\n",
    "> - **total_rooms**: Total number of rooms within the block (continuous)\n",
    "> - **total_bedrooms**: Total number of bedrooms within the block (continuous)\n",
    "> - **population**: Total population residing in the block (continuous)\n",
    "> - **households**: Total number of households in the block (continuous)\n",
    "> - **median_income**: Median income for households within the block (continuous, scaled and capped at 15.0)\n",
    "> - **ocean_proximity**: Proximity to the ocean (categorical: '<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36skGSrIhnh1",
   "metadata": {
    "id": "36skGSrIhnh1"
   },
   "source": [
    "### 1.2 Business Motivation\n",
    "- What is the **business problem** you are trying to solve?  \n",
    "> The business problem is to accurately predict median house values in California housing districts to support strategic decision-making in the real estate market. Accurate house price predictions enable stakeholders to:\n",
    "> - **For Homebuyers**: Make informed purchasing decisions and identify undervalued properties\n",
    "> - **For Real Estate Agents**: Provide accurate pricing guidance to clients and optimize listing strategies\n",
    "> - **For Investors**: Identify profitable investment opportunities and assess market trends\n",
    "> - **For Lenders**: Evaluate property values for mortgage underwriting and risk assessment\n",
    "> - **For Developers**: Make data-driven decisions about where to build and what price points to target\n",
    "> \n",
    "> The challenge lies in understanding which factors most significantly influence house prices and building a reliable predictive model that can generalize to new housing districts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0Q4BKyfAmsUE",
   "metadata": {
    "id": "0Q4BKyfAmsUE"
   },
   "source": [
    "- Who are the **stakeholders** involved (e.g., managers, teams, customers)?  \n",
    "> **Primary Stakeholders:**\n",
    "> - **Homebuyers and Home Sellers**: Need accurate market valuations to make informed decisions about buying or selling properties\n",
    "> - **Real Estate Agents and Brokers**: Require reliable price estimates to advise clients and set competitive listing prices\n",
    "> - **Real Estate Investment Firms**: Need accurate valuations to identify investment opportunities and manage portfolios\n",
    "> - **Mortgage Lenders and Banks**: Require property valuations for loan underwriting, risk assessment, and portfolio management\n",
    "> - **Property Developers and Construction Companies**: Need market insights to decide where to build and what price points to target\n",
    "> - **Real Estate Appraisers**: Can use models as a tool to support their professional valuations\n",
    "> - **Government Agencies**: May use predictions for property tax assessments and urban planning decisions\n",
    "> - **Real Estate Technology Platforms** (e.g., Zillow, Redfin): Rely on accurate predictions for their automated valuation models (AVMs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Bmre6FK1mt6v",
   "metadata": {
    "id": "Bmre6FK1mt6v"
   },
   "source": [
    "- What are the **potential benefits or costs of not solving** this problem?\n",
    "> **Benefits of Solving This Problem:**\n",
    "> - **Improved Decision-Making**: Stakeholders can make more informed decisions with accurate price predictions\n",
    "> - **Market Efficiency**: Better price transparency leads to more efficient real estate markets\n",
    "> - **Risk Reduction**: Lenders and investors can better assess and mitigate financial risks\n",
    "> - **Competitive Advantage**: Real estate professionals with superior pricing models gain market advantages\n",
    "> - **Time Savings**: Automated valuations reduce the time needed for manual appraisals\n",
    "> \n",
    "> **Costs of Not Solving This Problem:**\n",
    "> - **Financial Losses**: Overpricing leads to properties sitting on the market; underpricing results in lost revenue\n",
    "> - **Poor Investment Decisions**: Without accurate predictions, investors may choose suboptimal properties or miss opportunities\n",
    "> - **Increased Risk**: Lenders face higher default risks if property values are overestimated\n",
    "> - **Market Inefficiency**: Inaccurate pricing creates market distortions and reduces overall market efficiency\n",
    "> - **Competitive Disadvantage**: Companies without accurate pricing models lose business to competitors with better tools\n",
    "> - **Customer Dissatisfaction**: Homebuyers and sellers lose trust when valuations are consistently inaccurate\n",
    "> - **Regulatory Issues**: Inaccurate valuations can lead to compliance problems and legal issues for financial institutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0fe2cc",
   "metadata": {
    "id": "5e0fe2cc"
   },
   "source": [
    "## Section 2 \u2014 EDA (Data Understanding & Key Insights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uhdyLQ5Jd6Jn",
   "metadata": {
    "id": "uhdyLQ5Jd6Jn"
   },
   "source": [
    "Use this section to **understand your dataset and uncover key business-relevant patterns.** Feel free to include both tables and visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oZMl1-SQiIkf",
   "metadata": {
    "id": "oZMl1-SQiIkf"
   },
   "source": [
    "1. Mount your Google Drive.\n",
    "2. Set your working directory (if you\u2019re using the default, no changes are needed).\n",
    "3. Update the file name to match the dataset you selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cpHDWClthA-Z",
   "metadata": {
    "id": "cpHDWClthA-Z"
   },
   "outputs": [],
   "source": [
    "# For local execution (Jupyter Notebook)\n",
    "# If using Google Colab, uncomment the following lines:\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd /content/drive/MyDrive/Colab Notebooks\n",
    "\n",
    "# Verify the current working directory\n",
    "import os\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# Read data into jupyter notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read File - California Housing Prices dataset\n",
    "df = pd.read_csv(\"California Housing Prices.csv\")\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumn names:\\n{df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-3nFT9tfkvKA",
   "metadata": {
    "id": "-3nFT9tfkvKA"
   },
   "source": [
    "\n",
    "### 2.1 Dataset Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ulfQJ2gLm6Rh",
   "metadata": {
    "id": "ulfQJ2gLm6Rh"
   },
   "source": [
    "- Provide a clear, high-level description of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DOBCX9UVeAro",
   "metadata": {
    "id": "DOBCX9UVeAro"
   },
   "outputs": [],
   "source": [
    "# Dataset Overview\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Dataset dimensions\n",
    "print(f\"\\nDataset Shape: {df.shape[0]} rows \u00d7 {df.shape[1]} columns\")\n",
    "\n",
    "# Column information\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COLUMN INFORMATION\")\n",
    "print(\"=\" * 60)\n",
    "print(df.info())\n",
    "\n",
    "# Data types summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATA TYPES SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(df.dtypes)\n",
    "\n",
    "# Target variable identification\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TARGET VARIABLE\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Target Variable (y): median_house_value\")\n",
    "print(\"\\nPredictor Variables (X):\")\n",
    "predictors = [col for col in df.columns if col != 'median_house_value']\n",
    "for i, pred in enumerate(predictors, 1):\n",
    "    print(f\"  {i}. {pred}\")\n",
    "\n",
    "# Statistical summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STATISTICAL SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(df.describe())\n",
    "\n",
    "# First few rows\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FIRST 5 ROWS\")\n",
    "print(\"=\" * 60)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8l7oQHRCm-uN",
   "metadata": {
    "id": "8l7oQHRCm-uN"
   },
   "source": [
    "### 2.2 Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q7vSSdhnnFcJ",
   "metadata": {
    "id": "q7vSSdhnnFcJ"
   },
   "source": [
    "- Diagnose and handle data problems that could affect analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yGbsgnL-gotc",
   "metadata": {
    "id": "yGbsgnL-gotc"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DATA QUALITY CHECKS\n",
    "# ============================================================\n",
    "\n",
    "# 1. Check for missing values\n",
    "print(\"=\" * 60)\n",
    "print(\"MISSING VALUES CHECK\")\n",
    "print(\"=\" * 60)\n",
    "missing_values = df.isna().sum()\n",
    "missing_percent = (missing_values / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_values,\n",
    "    'Percentage': missing_percent\n",
    "})\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0]\n",
    "if len(missing_df) > 0:\n",
    "    print(missing_df)\n",
    "else:\n",
    "    print(\"\u2713 No missing values found!\")\n",
    "\n",
    "# 2. Check for duplicates\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DUPLICATES CHECK\")\n",
    "print(\"=\" * 60)\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicate_count}\")\n",
    "if duplicate_count > 0:\n",
    "    print(\"\u26a0 Warning: Duplicates found. Consider removing them.\")\n",
    "else:\n",
    "    print(\"\u2713 No duplicate rows found!\")\n",
    "\n",
    "# 3. Check for impossible/out-of-range values\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATA VALIDATION CHECKS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check for negative values where they shouldn't exist\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "print(\"\\nChecking for negative values in numeric columns:\")\n",
    "for col in numeric_cols:\n",
    "    negative_count = (df[col] < 0).sum()\n",
    "    if negative_count > 0:\n",
    "        print(f\"  \u26a0 {col}: {negative_count} negative values found\")\n",
    "    else:\n",
    "        print(f\"  \u2713 {col}: No negative values\")\n",
    "\n",
    "# Check ocean_proximity categories\n",
    "print(\"\\nChecking ocean_proximity categories:\")\n",
    "print(f\"  Unique values: {df['ocean_proximity'].unique()}\")\n",
    "print(f\"  Value counts:\\n{df['ocean_proximity'].value_counts()}\")\n",
    "\n",
    "# Check for extreme outliers in key variables\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"OUTLIER DETECTION (Using IQR Method)\")\n",
    "print(\"=\" * 60)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def detect_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "key_variables = ['median_house_value', 'median_income', 'housing_median_age', 'total_rooms']\n",
    "for var in key_variables:\n",
    "    if var in df.columns:\n",
    "        outliers, lower, upper = detect_outliers_iqr(df, var)\n",
    "        outlier_pct = (len(outliers) / len(df)) * 100\n",
    "        print(f\"\\n{var}:\")\n",
    "        print(f\"  Lower bound: {lower:.2f}, Upper bound: {upper:.2f}\")\n",
    "        print(f\"  Outliers: {len(outliers)} ({outlier_pct:.2f}%)\")\n",
    "\n",
    "# Handle missing values in total_bedrooms (if any)\n",
    "if df['total_bedrooms'].isna().sum() > 0:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"HANDLING MISSING VALUES\")\n",
    "    print(\"=\" * 60)\n",
    "    # Impute missing bedrooms with median\n",
    "    median_bedrooms = df['total_bedrooms'].median()\n",
    "    df['total_bedrooms'].fillna(median_bedrooms, inplace=True)\n",
    "    print(f\"\u2713 Imputed {df['total_bedrooms'].isna().sum()} missing values in total_bedrooms with median: {median_bedrooms}\")\n",
    "\n",
    "# Remove duplicates if found\n",
    "if duplicate_count > 0:\n",
    "    df = df.drop_duplicates()\n",
    "    print(f\"\\n\u2713 Removed {duplicate_count} duplicate rows\")\n",
    "    print(f\"  New dataset shape: {df.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATA QUALITY CHECK COMPLETE\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2A0EPeeOnCJx",
   "metadata": {
    "id": "2A0EPeeOnCJx"
   },
   "source": [
    "### 2.3 Descriptive Explorations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pkE--1VVnIMo",
   "metadata": {
    "id": "pkE--1VVnIMo"
   },
   "source": [
    "- The goal of data exploration is to **discover patterns, relationships, and stories** within your data before modeling. This step is not about following fixed rules \u2014 it\u2019s about curiosity, creativity, and developing intuition. You are encouraged to **freely explore** the data in ways that make sense for your project \u2014 visualize, compare, or test relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nvf3DURMmAUc",
   "metadata": {
    "id": "nvf3DURMmAUc"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DESCRIPTIVE EXPLORATIONS\n",
    "# ============================================================\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Set style for better-looking plots\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "except:\n",
    "    try:\n",
    "        plt.style.use('seaborn-darkgrid')\n",
    "    except:\n",
    "        plt.style.use('ggplot')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# 1. Distribution of Target Variable\n",
    "print(\"=\" * 60)\n",
    "print(\"1. TARGET VARIABLE DISTRIBUTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(df['median_house_value'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Median House Value ($)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of Median House Values')\n",
    "axes[0].axvline(df['median_house_value'].median(), color='red', linestyle='--', \n",
    "                label=f'Median: ${df[\"median_house_value\"].median():,.0f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(df['median_house_value'], vert=True)\n",
    "axes[1].set_ylabel('Median House Value ($)')\n",
    "axes[1].set_title('Box Plot of Median House Values')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTarget Variable Statistics:\")\n",
    "print(df['median_house_value'].describe())\n",
    "\n",
    "# 2. Geographic Distribution\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"2. GEOGRAPHIC DISTRIBUTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "scatter = ax.scatter(df['longitude'], df['latitude'], \n",
    "                    c=df['median_house_value'], cmap='viridis', \n",
    "                    alpha=0.6, s=20, edgecolors='black', linewidth=0.5)\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "ax.set_title('Geographic Distribution of House Values in California')\n",
    "plt.colorbar(scatter, label='Median House Value ($)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Correlation Analysis\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"3. CORRELATION ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calculate correlation matrix for numeric variables\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "correlation_matrix = numeric_df.corr()\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Matrix of Numeric Variables', fontsize=14, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show correlations with target variable\n",
    "print(\"\\nCorrelations with Median House Value:\")\n",
    "target_corr = correlation_matrix['median_house_value'].sort_values(ascending=False)\n",
    "print(target_corr)\n",
    "\n",
    "# 4. Distribution of Key Predictor Variables\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"4. DISTRIBUTION OF KEY PREDICTOR VARIABLES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Median Income\n",
    "axes[0, 0].hist(df['median_income'], bins=50, edgecolor='black', alpha=0.7, color='skyblue')\n",
    "axes[0, 0].set_xlabel('Median Income (scaled)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('Distribution of Median Income')\n",
    "\n",
    "# Housing Median Age\n",
    "axes[0, 1].hist(df['housing_median_age'], bins=30, edgecolor='black', alpha=0.7, color='lightgreen')\n",
    "axes[0, 1].set_xlabel('Housing Median Age (years)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].set_title('Distribution of Housing Median Age')\n",
    "\n",
    "# Total Rooms\n",
    "axes[1, 0].hist(df['total_rooms'], bins=50, edgecolor='black', alpha=0.7, color='salmon')\n",
    "axes[1, 0].set_xlabel('Total Rooms')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].set_title('Distribution of Total Rooms')\n",
    "\n",
    "# Population\n",
    "axes[1, 1].hist(df['population'], bins=50, edgecolor='black', alpha=0.7, color='plum')\n",
    "axes[1, 1].set_xlabel('Population')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].set_title('Distribution of Population')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. Relationship Between Key Variables and Target\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"5. RELATIONSHIPS WITH TARGET VARIABLE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Median Income vs House Value\n",
    "axes[0, 0].scatter(df['median_income'], df['median_house_value'], alpha=0.5, s=10)\n",
    "axes[0, 0].set_xlabel('Median Income (scaled)')\n",
    "axes[0, 0].set_ylabel('Median House Value ($)')\n",
    "axes[0, 0].set_title('Median Income vs House Value')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Housing Age vs House Value\n",
    "axes[0, 1].scatter(df['housing_median_age'], df['median_house_value'], alpha=0.5, s=10)\n",
    "axes[0, 1].set_xlabel('Housing Median Age (years)')\n",
    "axes[0, 1].set_ylabel('Median House Value ($)')\n",
    "axes[0, 1].set_title('Housing Age vs House Value')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Total Rooms vs House Value\n",
    "axes[1, 0].scatter(df['total_rooms'], df['median_house_value'], alpha=0.5, s=10)\n",
    "axes[1, 0].set_xlabel('Total Rooms')\n",
    "axes[1, 0].set_ylabel('Median House Value ($)')\n",
    "axes[1, 0].set_title('Total Rooms vs House Value')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Population vs House Value\n",
    "axes[1, 1].scatter(df['population'], df['median_house_value'], alpha=0.5, s=10)\n",
    "axes[1, 1].set_xlabel('Population')\n",
    "axes[1, 1].set_ylabel('Median House Value ($)')\n",
    "axes[1, 1].set_title('Population vs House Value')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Ocean Proximity Analysis\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"6. OCEAN PROXIMITY ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Box plot by ocean proximity\n",
    "df.boxplot(column='median_house_value', by='ocean_proximity', ax=axes[0])\n",
    "axes[0].set_xlabel('Ocean Proximity')\n",
    "axes[0].set_ylabel('Median House Value ($)')\n",
    "axes[0].set_title('House Values by Ocean Proximity')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Bar plot of average house values\n",
    "ocean_avg = df.groupby('ocean_proximity')['median_house_value'].mean().sort_values(ascending=False)\n",
    "ocean_avg.plot(kind='bar', ax=axes[1], color='teal', edgecolor='black')\n",
    "axes[1].set_xlabel('Ocean Proximity')\n",
    "axes[1].set_ylabel('Average Median House Value ($)')\n",
    "axes[1].set_title('Average House Values by Ocean Proximity')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nAverage House Values by Ocean Proximity:\")\n",
    "print(ocean_avg)\n",
    "\n",
    "# 7. Derived Variables\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"7. DERIVED VARIABLES ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create derived variables\n",
    "df['rooms_per_household'] = df['total_rooms'] / df['households']\n",
    "df['bedrooms_per_room'] = df['total_bedrooms'] / df['total_rooms']\n",
    "df['population_per_household'] = df['population'] / df['households']\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Rooms per household vs House Value\n",
    "axes[0].scatter(df['rooms_per_household'], df['median_house_value'], alpha=0.5, s=10)\n",
    "axes[0].set_xlabel('Rooms per Household')\n",
    "axes[0].set_ylabel('Median House Value ($)')\n",
    "axes[0].set_title('Rooms per Household vs House Value')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Bedrooms per room vs House Value\n",
    "axes[1].scatter(df['bedrooms_per_room'], df['median_house_value'], alpha=0.5, s=10)\n",
    "axes[1].set_xlabel('Bedrooms per Room')\n",
    "axes[1].set_ylabel('Median House Value ($)')\n",
    "axes[1].set_title('Bedrooms per Room vs House Value')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Population per household vs House Value\n",
    "axes[2].scatter(df['population_per_household'], df['median_house_value'], alpha=0.5, s=10)\n",
    "axes[2].set_xlabel('Population per Household')\n",
    "axes[2].set_ylabel('Median House Value ($)')\n",
    "axes[2].set_title('Population per Household vs House Value')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCorrelations of Derived Variables with House Value:\")\n",
    "derived_vars = ['rooms_per_household', 'bedrooms_per_room', 'population_per_household']\n",
    "for var in derived_vars:\n",
    "    corr = df[var].corr(df['median_house_value'])\n",
    "    print(f\"  {var}: {corr:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DESCRIPTIVE EXPLORATION COMPLETE\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kcmZPfwDnDWY",
   "metadata": {
    "id": "kcmZPfwDnDWY"
   },
   "source": [
    "### 2.4 Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JuOIcAocnJs2",
   "metadata": {
    "id": "JuOIcAocnJs2"
   },
   "source": [
    "In this section, summarize **what you discovered** from your data exploration (Section 2.3).  \n",
    "Your goal is to **translate observations into insights** that connect back to your business question.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jemt483WnR2D",
   "metadata": {
    "id": "jemt483WnR2D"
   },
   "source": [
    "**Key Insights from Data Exploration:**\n",
    "\n",
    "> **1. Median Income is the Strongest Predictor**\n",
    "> - Median income shows the strongest positive correlation (approximately 0.69) with median house value, indicating that income levels are the most influential factor in determining house prices. This makes intuitive business sense: higher-income areas can support higher property values. The relationship appears relatively linear, though there's a notable cap at higher income levels (scaled value of 15.0), suggesting potential data preprocessing or economic constraints.\n",
    "\n",
    "> **2. Geographic Location Strongly Influences House Values**\n",
    "> - The geographic visualization reveals clear spatial patterns: coastal areas (particularly near the ocean and bays) show significantly higher house values compared to inland regions. Ocean proximity analysis shows that properties near the ocean command premium prices, with ISLAND locations having the highest average values, followed by NEAR OCEAN and NEAR BAY categories. This geographic premium is a critical factor for real estate stakeholders to consider when pricing properties or making investment decisions.\n",
    "\n",
    "> **3. Derived Variables Reveal Important Housing Characteristics**\n",
    "> - The derived variable \"rooms_per_household\" shows a meaningful positive correlation with house values, suggesting that larger homes (more rooms per household) command higher prices. This insight helps explain why total_rooms alone may not be as predictive\u2014it's the ratio relative to households that matters more. Additionally, the analysis reveals that housing age has a complex relationship with value, with both very new and very old properties showing different value patterns.\n",
    "\n",
    "> **4. Data Quality and Distribution Characteristics**\n",
    "> - The dataset is generally clean with minimal missing values (primarily in total_bedrooms, which was handled through imputation). However, the target variable (median_house_value) shows a right-skewed distribution with a notable cap at $500,000, suggesting potential data preprocessing or economic constraints. The presence of outliers in variables like total_rooms and population indicates the need for careful feature engineering and potentially robust modeling approaches that can handle these extreme values.\n",
    "\n",
    "> **5. Unexpected Patterns and Business Implications**\n",
    "> - An interesting finding is that population density (population_per_household) shows a negative correlation with house values in some areas, suggesting that overcrowded areas may actually have lower property values\u2014a counterintuitive finding that could indicate urban vs. suburban preferences or quality-of-life factors. Additionally, the correlation analysis reveals that some variables (like total_bedrooms and total_rooms) are highly correlated with each other, suggesting potential multicollinearity that should be addressed in modeling through feature selection or dimensionality reduction techniques.  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}